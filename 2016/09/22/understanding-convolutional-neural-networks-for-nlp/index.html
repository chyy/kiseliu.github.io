<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Helvetica Neue:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="CNN,Classification," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="æœ¬æ–‡è¯‘è‡ªUNDERSTANDING CONVOLUTIONAL NEURAL NETWORKS FOR NLPã€‚
å½“æˆ‘ä»¬å¬åˆ°CNNçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸€ä¸‹å°±ä¼šæƒ³åˆ°è®¡ç®—æœºè§†è§‰ã€‚CNNsåœ¨å›¾åƒåˆ†ç±»çš„é‡å¤§çªç ´ä¸Šåšå‡ºäº†å·¨å¤§çš„è´¡çŒ®ï¼Œä»Facebookçš„è‡ªåŠ¨å›¾åƒæ ‡æ³¨åˆ°è‡ªåŠ¨é©¾é©¶ï¼ŒCNNså½“ä»Šå¤§å¤šæ•°è®¡ç®—æœºè§†è§‰ç³»ç»Ÿçš„æ ¸å¿ƒã€‚
æœ€è¿‘ï¼Œæˆ‘ä»¬ä¹Ÿå¼€å§‹åº”ç”¨CNNsè§£å†³NLPä¸­é‡åˆ°çš„é—®é¢˜ï¼Œå–å¾—äº†ä¸€äº›æœ‰è¶£çš„ç»“æœã€‚æœ¬æ–‡å°†å°½åŠ›è§£é‡Šä»€ä¹ˆæ˜¯CNN">
<meta property="og:type" content="article">
<meta property="og:title" content="Understanding Convolutional Neural Networks for NLP">
<meta property="og:url" content="http://github.com/kiseliu/2016/09/22/understanding-convolutional-neural-networks-for-nlp/index.html">
<meta property="og:site_name" content="Welcome to kiseliu's homepage">
<meta property="og:description" content="æœ¬æ–‡è¯‘è‡ªUNDERSTANDING CONVOLUTIONAL NEURAL NETWORKS FOR NLPã€‚
å½“æˆ‘ä»¬å¬åˆ°CNNçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸€ä¸‹å°±ä¼šæƒ³åˆ°è®¡ç®—æœºè§†è§‰ã€‚CNNsåœ¨å›¾åƒåˆ†ç±»çš„é‡å¤§çªç ´ä¸Šåšå‡ºäº†å·¨å¤§çš„è´¡çŒ®ï¼Œä»Facebookçš„è‡ªåŠ¨å›¾åƒæ ‡æ³¨åˆ°è‡ªåŠ¨é©¾é©¶ï¼ŒCNNså½“ä»Šå¤§å¤šæ•°è®¡ç®—æœºè§†è§‰ç³»ç»Ÿçš„æ ¸å¿ƒã€‚
æœ€è¿‘ï¼Œæˆ‘ä»¬ä¹Ÿå¼€å§‹åº”ç”¨CNNsè§£å†³NLPä¸­é‡åˆ°çš„é—®é¢˜ï¼Œå–å¾—äº†ä¸€äº›æœ‰è¶£çš„ç»“æœã€‚æœ¬æ–‡å°†å°½åŠ›è§£é‡Šä»€ä¹ˆæ˜¯CNN">
<meta property="og:image" content="http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif">
<meta property="og:image" content="http://docs.gimp.org/en/images/filters/examples/convolution-blur.png">
<meta property="og:image" content="http://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-blur.jpg">
<meta property="og:image" content="http://docs.gimp.org/en/images/filters/examples/convolution-edge-detect1.png">
<meta property="og:image" content="http://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-edge-detect.jpg">
<meta property="og:image" content="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-07-at-7.26.20-AM.png">
<meta property="og:image" content="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-12.05.40-PM.png">
<meta property="og:image" content="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-9.47.41-AM.png">
<meta property="og:image" content="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-10.18.08-AM.png">
<meta property="og:image" content="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-2.18.38-PM.png">
<meta property="og:image" content="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-8.03.47-AM.png">
<meta property="og:updated_time" content="2016-09-22T09:50:55.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Understanding Convolutional Neural Networks for NLP">
<meta name="twitter:description" content="æœ¬æ–‡è¯‘è‡ªUNDERSTANDING CONVOLUTIONAL NEURAL NETWORKS FOR NLPã€‚
å½“æˆ‘ä»¬å¬åˆ°CNNçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸€ä¸‹å°±ä¼šæƒ³åˆ°è®¡ç®—æœºè§†è§‰ã€‚CNNsåœ¨å›¾åƒåˆ†ç±»çš„é‡å¤§çªç ´ä¸Šåšå‡ºäº†å·¨å¤§çš„è´¡çŒ®ï¼Œä»Facebookçš„è‡ªåŠ¨å›¾åƒæ ‡æ³¨åˆ°è‡ªåŠ¨é©¾é©¶ï¼ŒCNNså½“ä»Šå¤§å¤šæ•°è®¡ç®—æœºè§†è§‰ç³»ç»Ÿçš„æ ¸å¿ƒã€‚
æœ€è¿‘ï¼Œæˆ‘ä»¬ä¹Ÿå¼€å§‹åº”ç”¨CNNsè§£å†³NLPä¸­é‡åˆ°çš„é—®é¢˜ï¼Œå–å¾—äº†ä¸€äº›æœ‰è¶£çš„ç»“æœã€‚æœ¬æ–‡å°†å°½åŠ›è§£é‡Šä»€ä¹ˆæ˜¯CNN">
<meta name="twitter:image" content="http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://github.com/kiseliu/2016/09/22/understanding-convolutional-neural-networks-for-nlp/"/>

  <title> Understanding Convolutional Neural Networks for NLP | Welcome to kiseliu's homepage </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
<!-- hexo-inject:begin --><!-- hexo-inject:end --><script>
  window.fbAsyncInit = function() {
    FB.init({
      appId      : '',
      xfbml      : true,
      version    : 'v2.6'
    });
  };

  (function(d, s, id){
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) {return;}
     js = d.createElement(s); js.id = id;
     js.src = "//connect.facebook.net/en/sdk.js";
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script>











  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Welcome to kiseliu's homepage</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Here's a dream chaser.</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-search">
          <a href="/search" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-search"></i> <br />
            
            Search
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Understanding Convolutional Neural Networks for NLP
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-09-22T10:28:17+08:00" content="2016-09-22">
              2016-09-22
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/09/22/understanding-convolutional-neural-networks-for-nlp/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/09/22/understanding-convolutional-neural-networks-for-nlp/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><strong>æœ¬æ–‡è¯‘è‡ª<a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/" target="_blank" rel="external">UNDERSTANDING CONVOLUTIONAL NEURAL NETWORKS FOR NLP</a></strong>ã€‚</p>
<p>å½“æˆ‘ä»¬å¬åˆ°CNNçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸€ä¸‹å°±ä¼šæƒ³åˆ°è®¡ç®—æœºè§†è§‰ã€‚CNNsåœ¨å›¾åƒåˆ†ç±»çš„é‡å¤§çªç ´ä¸Šåšå‡ºäº†å·¨å¤§çš„è´¡çŒ®ï¼Œä»Facebookçš„è‡ªåŠ¨å›¾åƒæ ‡æ³¨åˆ°è‡ªåŠ¨é©¾é©¶ï¼ŒCNNså½“ä»Šå¤§å¤šæ•°è®¡ç®—æœºè§†è§‰ç³»ç»Ÿçš„æ ¸å¿ƒã€‚</p>
<p>æœ€è¿‘ï¼Œæˆ‘ä»¬ä¹Ÿå¼€å§‹åº”ç”¨CNNsè§£å†³NLPä¸­é‡åˆ°çš„é—®é¢˜ï¼Œå–å¾—äº†ä¸€äº›æœ‰è¶£çš„ç»“æœã€‚æœ¬æ–‡å°†å°½åŠ›è§£é‡Šä»€ä¹ˆæ˜¯CNNsï¼Œå®ƒæ€ä¹ˆç”¨äºNLPã€‚CNNs èƒŒåçš„ç›´è§‰è®©ç†è§£è®¡ç®—æœºè§†è§‰çš„åº”ç”¨æ¡ˆä¾‹æ›´å®¹æ˜“ï¼Œå› æ­¤æˆ‘ä»¬å°†ä»è¿™é‡Œå¼€å§‹ï¼Œç„¶åé€æ¸è½¬å‘NLPã€‚</p>
<h1 id="What-is-convolution"><a href="#What-is-convolution" class="headerlink" title="What is convolution?"></a>What is convolution?</h1><p>å¯¹äºæˆ‘æ¥è¯´ç†è§£<strong>å·ç§¯</strong>æœ€ç®€å•çš„æ–¹æ³•æ˜¯æŠŠå®ƒæƒ³æˆä¸€ä¸ªåº”ç”¨åˆ°çŸ©é˜µä¸Šçš„æ»‘åŠ¨çª—å£å‡½æ•°ã€‚çœ‹ä¸€ä¸‹å›¾åƒå¯èƒ½æ›´æ¸…æ¥šï¼š<br><img src="http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif" alt="" title="Convolution with 3Ã—3 Filter. Source: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution"><br>æƒ³è±¡å·¦è¾¹çš„çŸ©é˜µè¡¨ç¤ºä¸€å¼ é»‘ç™½çš„å›¾ç‰‡ã€‚æ¯ä¸€ä¸ªè¾“å…¥è¡¨ç¤ºä¸€ä¸ªåƒç´ ï¼Œ0è¡¨ç¤ºé»‘è‰²ï¼Œ1è¡¨ç¤ºç™½è‰²(å¯¹äºç°åº¦å›¾æ¥è¯´ï¼Œå–å€¼é€šå¸¸ä»‹äº0ï½255)ã€‚æ»‘åŠ¨çª—å£å«åš<strong>kernel</strong>, <strong>filter</strong>, æˆ–è€… <strong>feature detector</strong>ã€‚è¿™é‡Œæˆ‘ä»¬ç”¨ä¸€ä¸ª 3x3 çš„filterï¼Œå’ŒåŸå§‹çŸ©é˜µåšç‚¹ä¹˜ï¼Œç„¶åç›¸åŠ ã€‚ä¸ºäº†å¾—åˆ°æ‰€æœ‰çš„å·ç§¯ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨æ•´ä¸ªçŸ©é˜µä¸Šæ»‘åŠ¨filterå¯¹æ¯ä¸ªå…ƒç´ éƒ½è¿™æ ·åš (To get the full convolution we do this for each element by sliding the filter over the whole matrix.)ã€‚</p>
<p>ä½ å¯èƒ½ä¼šæƒ³ç”¨è¿™ä¸ªä½ å¯ä»¥åšä»€ä¹ˆï¼Ÿè¿™é‡Œæ˜¯ä¸€äº›ç›´æ¥çš„ä¾‹å­ã€‚<br>å¯¹æ¯ä¸ªåƒç´ ï¼Œç»“åˆå®ƒçš„é‚»å€¼åšå¹³å‡æ¥æ¨¡ç³Šå›¾åƒï¼š<br><img src="http://docs.gimp.org/en/images/filters/examples/convolution-blur.png" alt=""> <img src="http://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-blur.jpg" alt="æ¥æº: http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/"><br>æ ¹æ®åƒç´ å’Œå®ƒçš„è¿‘é‚»åƒç´ çš„å·®å¼‚æ¥æ£€æµ‹è¾¹ç¼˜ï¼š<br>(To understand this one intuitively, think about what happens in parts of the image that are smooth, where a pixel color equals that of its neighbors: The additions cancel and the resulting value is 0, or black. If thereâ€™s a sharp edge in intensity, a transition from white to black for example, you get a large difference and a resulting white value)<br><img src="http://docs.gimp.org/en/images/filters/examples/convolution-edge-detect1.png" alt="æ¥æº: http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/"> <img src="http://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-edge-detect.jpg" alt=""><br><a href="http://docs.gimp.org/en/plug-in-convmatrix.html" target="_blank" rel="external">GIMP manual</a> æœ‰ä¸€äº›å…¶å®ƒçš„ä¾‹å­ã€‚ä¸ºäº†ç†è§£æ›´å¤šå…³äºå·ç§¯æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œæˆ‘æ¨èçœ‹ä¸€ä¸‹<a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/" target="_blank" rel="external">Chris Olahâ€™s post on the topic</a>ã€‚</p>
<h1 id="What-are-convolutional-neural-networks"><a href="#What-are-convolutional-neural-networks" class="headerlink" title="What are convolutional neural networks?"></a>What are convolutional neural networks?</h1><p>ç°åœ¨ä½ çŸ¥é“ä»€ä¹ˆæ˜¯å·ç§¯äº†ï¼Œä½†æ˜¯ä»€ä¹ˆæ˜¯CNNsï¼ŸCNNsåªæ˜¯å‡ å±‚å…·æœ‰éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œåƒ <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" target="_blank" rel="external">ReLU</a> or <a href="https://reference.wolfram.com/language/ref/Tanh.html" target="_blank" rel="external">tanh</a> çš„å·ç§¯å±‚ã€‚åœ¨ä¼ ç»Ÿçš„å‰é¦ˆç¥ç»ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬è¿æ¥æ¯ä¸ªè¾“å…¥ç¥ç»å…ƒåˆ°ä¸‹ä¸€å±‚çš„æ¯ä¸ªè¾“å‡ºç¥ç»å…ƒã€‚è¿™ä¹Ÿå«åšå…¨è¿æ¥å±‚ï¼Œæˆ–è€…ä»¿å°„å±‚ã€‚åœ¨CNNsä¸­ï¼Œæˆ‘ä»¬ä¸è¿™æ ·åšã€‚ç›¸åï¼Œæˆ‘ä»¬åœ¨è¾“å…¥å±‚ä½¿ç”¨å·ç§¯æ¥è®¡ç®—è¾“å‡ºã€‚è¿™ä¼šå¾—åˆ°ä¸€ä¸ªå±€éƒ¨è¿æ¥ï¼Œä¹Ÿå°±æ˜¯è¾“å…¥çš„æ¯ä¸ªå°åŒºåŸŸéƒ½è¢«è¿æ¥åˆ°è¾“å‡ºçš„æ¯ä¸ªç¥ç»å…ƒã€‚æ¯å±‚åº”ç”¨ä¸åŒçš„filtersï¼Œå¯ä»¥æ˜¯æˆç™¾ä¸Šåƒä¸ªfiltersï¼Œç„¶åæŠŠå®ƒä»¬çš„ç»“æœè¿æ¥èµ·æ¥ã€‚è¿™ä¹Ÿå«åšpooling (subsampling) layersï¼Œæˆ‘ä»¬åé¢ä¼šè®²ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œæ ¹æ®ä½ æƒ³è¦è¿›è¡Œçš„ä»»åŠ¡ï¼Œ<strong>CNNä¼šè‡ªåŠ¨å­¦ä¹ filtersçš„å€¼</strong>ã€‚æ¯”å¦‚åœ¨å›¾åƒåˆ†ç±»ä¸­ï¼Œç¬¬ä¸€å±‚CNNå¯èƒ½ä¼šä»åŸå§‹çš„åƒç´ ä¸­å­¦ä¹ æ£€æµ‹è¾¹ç¼˜ï¼Œç„¶ååœ¨ç¬¬äºŒå±‚ç”¨è¾¹ç¼˜æ¥æ£€æµ‹ç®€å•çš„å½¢çŠ¶ï¼Œç”¨è¿™äº›å½¢çŠ¶æ¥å¾—åˆ°æ›´é«˜å±‚æ¬¡çš„ç‰¹å¾ï¼Œæ¯”å¦‚åœ¨æ›´æ·±å±‚çš„é¢éƒ¨å½¢çŠ¶ã€‚æœ€åä¸€å±‚æ˜¯ä½¿ç”¨è¿™äº›é«˜é˜¶ç‰¹å¾çš„åˆ†ç±»å™¨ã€‚<br><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-07-at-7.26.20-AM.png" alt=""><br>è¯¥è®¡ç®—æœ‰ä¸¤æ–¹é¢å€¼å¾—æ³¨æ„ï¼š<strong>Location Invariance</strong> å’Œ <strong>Compositionality</strong>ã€‚å‡å¦‚ä½ æƒ³è¦åŒºåˆ†å›¾ç‰‡ä¸Šæ˜¯å¦æœ‰å¤§è±¡ğŸ˜ï¼Œå› ä¸ºä½ åœ¨æ•´ä¸ªå›¾åƒä¸Šæ»‘åŠ¨ä½ çš„filtersï¼Œä½ å¹¶ä¸åœ¨æ„å¤§è±¡å‡ºç°åœ¨é‚£é‡Œã€‚åœ¨å®è·µä¸­ï¼Œpoolingç»™ä½ æä¾› invariance åˆ° translationï¼Œrotation å’Œ scalingç­‰ç­‰ã€‚ç¬¬äºŒä¸ªä¸»è¦çš„æ–¹é¢æ˜¯ (local) compositionalityã€‚æ¯ä¸€ä¸ªfilteréƒ½æŠŠä½é˜¶ç‰¹å¾çš„ä¸€ä¸ªå±€éƒ¨patchæ„æˆæ›´é«˜é˜¶çš„è¡¨ç¤ºï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆCNNsåœ¨è®¡ç®—æœºè§†è§‰ä¸­å¦‚æ­¤å¼ºå¤§çš„åŸå› ã€‚ç›´è§‰ä¸Šè¿™æ˜¯åˆç†çš„ï¼Œä½ ä»åƒç´ æ„å»ºå‡ºè¾¹ç¼˜ï¼Œä»è¾¹ç¼˜æ„å»ºå‡ºå½¢çŠ¶ï¼Œä»å½¢çŠ¶æ„å»ºå‡ºæ›´å¤æ‚çš„å¯¹è±¡ã€‚</p>
<h1 id="So-how-does-any-of-this-apply-to-NLP"><a href="#So-how-does-any-of-this-apply-to-NLP" class="headerlink" title="So, how does any of this apply to NLP?"></a>So, how does any of this apply to NLP?</h1><p>å’Œå›¾åƒåƒç´ ä¸åŒï¼Œå¤§å¤šæ•°NLPä»»åŠ¡çš„è¾“å…¥æ˜¯è¡¨ç¤ºæˆçŸ©é˜µçš„å¥å­æˆ–è€…æ–‡æ¡£ã€‚çŸ©é˜µçš„æ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªtokenï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªwordï¼Œä½†æ˜¯å®ƒå¯ä»¥æ˜¯ä¸€ä¸ªå­—ç¬¦ã€‚ä¹Ÿå°±æ˜¯è¯´æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªå‘é‡ï¼Œå®ƒä»£è¡¨ä¸€ä¸ªwordã€‚é€šå¸¸æ¥è¯´ï¼Œè¿™äº›å‘é‡æ˜¯word embeddings(ä½ç»´è¡¨ç¤º)ï¼Œåƒ word2vec æˆ–è€… GloVeï¼Œä½†æ˜¯ä¹Ÿå¯ä»¥æ˜¯ç´¢å¼•è¯åˆ°è¯æ±‡è¡¨çš„one-hotç¼–ç çš„å‘é‡ã€‚å¯¹äºä¸€ä¸ªä½¿ç”¨100ç»´embeddingçš„åŒ…å«10ä¸ªwordçš„å¥å­ï¼Œæˆ‘ä»¬çš„è¾“å…¥æ˜¯ä¸€ä¸ª10*100çš„çŸ©é˜µï¼Œè¿™å°±æ˜¯æˆ‘ä»¬çš„â€œå›¾åƒâ€ã€‚</p>
<p>åœ¨è®¡ç®—æœºè§†è§‰ä¸­ï¼Œfiltersåœ¨å›¾åƒçš„å±€éƒ¨patchesä¸Šæ»‘åŠ¨ï¼Œä½†æ˜¯åœ¨NLPé¢†åŸŸï¼Œæˆ‘ä»¬å¸¸å¸¸ä½¿ç”¨åœ¨çŸ©é˜µçš„æ•´è¡Œ(words)ä¸Šæ»‘åŠ¨çš„filtersã€‚ä¹Ÿå°±æ˜¯filtersçš„å®½å’Œè¾“å…¥çŸ©é˜µçš„å®½åº¦ç›¸åŒã€‚é«˜æˆ–è€…è¯´åŒºåŸŸçš„å¤§å°å¯èƒ½ä¼šå˜åŒ–ï¼Œä½†æ˜¯å¸¸ç”¨çš„æ»‘åŠ¨çª—å£ä¸€æ¬¡åŒ…å«2-5ä¸ªwords(èŠ±å‡ åˆ†é’Ÿå°è¯•ç†è§£ä¸€ä¸‹è¿™å¹…å›¾ï¼Œä»¥åŠç»´åº¦æ˜¯å¦‚ä½•è®¡ç®—çš„ã€‚ç°åœ¨ä½ å¯ä»¥å…ˆå¿½ç•¥poolingï¼Œåç»­æˆ‘ä»¬ä¼šè§£é‡Š)ï¼š<br><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-12.05.40-PM.png" alt="" title="Illustration of a Convolutional Neural Network (CNN) architecture for sentence classification. Here we depict three filter region sizes: 2, 3 and 4, each of which has 2 filters. Every filter performs convolution on the sentence matrix and generates (variable-length) feature maps. Then 1-max pooling is performed over each map, i.e., the largest number from each feature map is recorded. Thus a univariate feature vector is generated from all six maps, and these 6 features are concatenated to form a feature vector for the penultimate layer. The final softmax layer then receives this feature vector as input and uses it to classify the sentence; here we assume binary classification and hence depict two possible output states. Source: Zhang, Y., &amp; Wallace, B. (2015). A Sensitivity Analysis of (and Practitionersâ€™ Guide to) Convolutional Neural Networks for Sentence Classification."><br>æˆ‘ä»¬åœ¨è®¡ç®—æœºè§†è§‰ä¸­æœ‰çš„è‰¯å¥½çš„ç›´è§‰æ˜¯ä»€ä¹ˆï¼ŸLocation Invariance å’Œ local Compositionality åœ¨å›¾åƒæ–¹é¢æ˜¯åˆç†çš„ï¼Œä½†æ˜¯åœ¨NLPä¸­å¹¶ä¸æ˜¯ã€‚ä½ å¯èƒ½å¾ˆå…³å¿ƒwordåˆ°åº•å‡ºç°åœ¨å¥å­ä¸­çš„å“ªä¸ªåœ°æ–¹ï¼Ÿç›¸é‚»çš„åƒç´ å¾ˆå¯èƒ½æ˜¯è¯­ä¹‰ç›¸å…³çš„(ç›¸åŒå¯¹è±¡çš„ä¸€éƒ¨åˆ†)ï¼Œä½†æ˜¯è¿™ç§å…³ç³»å¯¹wordså¹¶ä¸æ€»æ˜¯æˆç«‹ã€‚åœ¨è®¸å¤šè¯­è¨€ä¸­ï¼ŒçŸ­è¯­çš„æŸäº›éƒ¨åˆ†å¯èƒ½è¢«å‡ ä¸ªå…¶ä»–wordsç»™åˆ†å¼€ã€‚compositional æ–¹é¢ä¹Ÿä¸æ˜æ˜¾ã€‚å¾ˆæ˜¾ç„¶ï¼Œwordsä»¥æŸäº›æ–¹å¼ç»„æˆåœ¨ä¸€èµ·ï¼Œæ¯”å¦‚ï¼Œå½¢å®¹è¯ä¿®é¥°åè¯ï¼Œä½†æ˜¯è¿™åˆ°åº•å¦‚ä½•ç»„æˆï¼Œé«˜é˜¶è¡¨ç¤ºå®é™…ä¸Šè¯´æ˜äº†ä»€ä¹ˆå¹¶ä¸åƒè®¡ç®—æœºè§†è§‰ä¸­çš„åº”ç”¨æ¡ˆä¾‹é‚£æ ·æ˜æ˜¾ã€‚</p>
<p>è€ƒè™‘æ‰€æœ‰çš„è¿™äº›ï¼ŒCNNsä¼¼ä¹å¹¶ä¸æ˜¯å¾ˆé€‚åˆNLPé¢†åŸŸçš„ä»»åŠ¡ã€‚<a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" target="_blank" rel="external">Recurrent Neural Networks</a>åœ¨ç›´è§‰ä¸Šæ›´åˆç†ã€‚å®ƒä»¬æ¨¡ä»¿æˆ‘ä»¬æ€ä¹ˆå¤„ç†è¯­è¨€(æˆ–è€…æˆ‘ä»¬è®¤ä¸ºæˆ‘ä»¬å¦‚ä½•å¤„ç†è¯­è¨€): ä»å·¦å¾€å³æŒ‰é¡ºåºè¯»ã€‚å¹¸è¿åœ°æ˜¯ï¼Œè¿™å¹¶ä¸æ„å‘³ç€CNNsä¸èµ·ä½œç”¨ã€‚<a href="https://en.wikipedia.org/wiki/All_models_are_wrong" target="_blank" rel="external">All models are wrong, but some are sueful</a>ã€‚CNNsåœ¨NLPé—®é¢˜ä¸Šè¡¨ç°åœ°ç›¸å½“å¥½ã€‚ç®€å•çš„<a href="https://en.wikipedia.org/wiki/Bag-of-words_model" target="_blank" rel="external">è¯è¢‹æ¨¡å‹</a>å¾ˆæ˜¾ç„¶è¿‡äºç®€å•ï¼Œæœ‰ç€ä¸æ­£ç¡®çš„å‡è®¾ï¼Œä½†æ˜¯å°½ç®¡å¦‚æ­¤ï¼Œè¿™äº›å¹´å®ƒéƒ½æ˜¯æ ‡å‡†çš„æ–¹æ³•ï¼Œå¹¶ä¸”ä¹Ÿæœ‰ä¸é”™çš„ç»“æœã€‚</p>
<p>CNNsçš„ä¸€ä¸ªç‰¹ç‚¹æ˜¯é€Ÿåº¦å¿«ï¼Œéå¸¸å¿«ã€‚å·ç§¯æ˜¯è®¡ç®—æœºå›¾åƒå­¦çš„ä¸€ä¸ªæ ¸å¿ƒéƒ¨åˆ†ï¼Œåœ¨åŸºäºGPUsçš„ç¡¬ä»¶å±‚é¢ä¸Šå®ç°ã€‚å’Œn-gramsç›¸æ¯”ï¼ŒCNNså°±è¡¨ç¤ºè€Œè¨€ä¹Ÿæ˜¯å¾ˆé«˜æ•ˆçš„ã€‚å¯¹äºå¾ˆå¤§çš„è¯æ±‡è¡¨ï¼Œè®¡ç®—è¶…è¿‡ 3-gramsçš„ä»»åŠ¡çš„ä»£ä»·å¾ˆå¿«å°±éå¸¸æ˜‚è´µã€‚å³ä½¿æ˜¯Googleä¹Ÿä¸æä¾›è¶…è¿‡5-gramsçš„ä»»åŠ¡ã€‚Convolutional Filtersè‡ªåŠ¨å­¦ä¹ å¥½çš„è¡¨ç¤ºï¼Œä¸éœ€è¦è¡¨ç¤ºæ•´ä¸ªè¯æ±‡è¡¨ã€‚filtersçš„å¤§å°è¶…è¿‡5ä¹Ÿæ˜¯éå¸¸åˆç†çš„ã€‚æˆ‘å¯èƒ½ä¼šæƒ³ï¼Œåœ¨ç¬¬ä¸€å±‚è®¸å¤šå­¦ä¹ å‡ºæ¥çš„filtersæ˜¯åœ¨å­¦ä¹ ç±»ä¼¼(ä½†ä¸é™äº)n-gramsçš„ç‰¹å¾ï¼Œåªæ˜¯ç”¨ä¸€ç§æ›´å‹ç¼©çš„æ–¹å¼æ¥è¡¨ç¤ºå®ƒä»¬ã€‚</p>
<h1 id="CNN-Hyperparameters"><a href="#CNN-Hyperparameters" class="headerlink" title="CNN Hyperparameters"></a>CNN Hyperparameters</h1><p>åœ¨è§£é‡ŠCNNså¦‚ä½•åº”ç”¨äºNLPä»»åŠ¡ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆçœ‹ä¸€çœ‹æ„å»ºCNNæ—¶ï¼Œä½ éœ€è¦åšçš„ä¸€äº›é€‰æ‹©ã€‚å¸Œæœ›è¿™ä¼šå¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è¿™ä¸ªé¢†åŸŸçš„æ–‡çŒ®ã€‚</p>
<h1 id="Narrow-VS-Wide-Convolution"><a href="#Narrow-VS-Wide-Convolution" class="headerlink" title="Narrow VS. Wide Convolution"></a>Narrow VS. Wide Convolution</h1><p>å½“æˆ‘åœ¨ä¸Šé¢è§£é‡Šå·ç§¯çš„æ—¶å€™ï¼Œæˆ‘å¿½ç•¥äº†æˆ‘ä»¬å¦‚ä½•åº”ç”¨filterçš„ä¸€äº›ç»†èŠ‚ã€‚åœ¨çŸ©é˜µä¸­å¿ƒåº”ç”¨ä¸€ä¸ª3Ã—3 çš„filterå·¥ä½œçš„å¾ˆå¥½ï¼Œä½†æ˜¯åœ¨è¾¹ç¼˜å‘¢ï¼Ÿä½ å¦‚ä½•å°†filter åº”ç”¨åœ¨çŸ©é˜µçš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œè¿™ä¸ªå…ƒç´ çš„ä¸Šé¢å’Œå·¦è¾¹éƒ½æ²¡æœ‰ç›¸é‚»å…ƒç´ ï¼Ÿä½ å¯ä»¥ä½¿ç”¨0å¡«å……ã€‚æ‰€æœ‰è½åœ¨çŸ©é˜µå¤–é¢çš„å…ƒç´ éƒ½å–é›¶ã€‚è¿™æ ·åšï¼Œä½ å°±å¯ä»¥æŠŠfilteråº”ç”¨åˆ°è¾“å…¥çŸ©é˜µçš„æ¯ä¸€ä¸ªå…ƒç´ ä¸Šï¼Œç„¶åå¾—åˆ°ä¸€ä¸ªæ›´å¤§æˆ–è€…ç›¸ç­‰å¤§å°çš„è¾“å‡ºã€‚åŠ å…¥é›¶å¡«å……ä¹Ÿå«åšwide convolutionï¼Œä¸ä½¿ç”¨é›¶å¡«å……å°±æ˜¯narrow convolutionã€‚ä¸€ä¸ª1ç»´çš„ä¾‹å­å¦‚ä¸‹ï¼š<br><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-9.47.41-AM.png" alt="" title="Narrow vs. Wide Convolution. Filter size 5, input size 7. Source: A Convolutional Neural Network for Modelling Sentences (2014)"><br>å¯ä»¥çœ‹åˆ°ï¼Œå½“ä½ ç”¨ä¸€ä¸ªç›¸å¯¹è¾“å…¥æ¥è¯´è¾ƒå¤§çš„filteræ—¶ï¼Œwide convolutionå¾ˆæœ‰ç”¨çš„ï¼Œç”šè‡³æ˜¯å¿…é¡»çš„ã€‚åœ¨ä¸Šå›¾ï¼Œnarrow convolution å¾—åˆ°å¤§å°ä¸º \((7-5)+1=3\) çš„è¾“å‡ºï¼Œwide convolutionçš„è¾“å‡ºå¤§å°ä¸º \((7+2*4-5)+1=11\)ã€‚æ›´ä¸€èˆ¬åœ°ï¼Œè¾“å‡ºå¤§å°çš„å…¬å¼æ˜¯ \(n_{out}=(n_{in}+2*n_{padding}-n_{filter})+1\)ã€‚</p>
<h1 id="Stride-size"><a href="#Stride-size" class="headerlink" title="Stride size"></a>Stride size</h1><p>and consecutive applications of the filter overlapped. A larger stride size leads to fewer applications of the filter and a smaller output size. The following from the Stanford cs231 website shows stride sizes of 1 and 2 applied to a one-dimensional input:<br> å·ç§¯çš„å¦ä¸€ä¸ªè¶…å‚æ˜¯stride sizeï¼Œå®ƒå®šä¹‰æ¯ä¸€æ­¥ä½ çš„filterç§»åŠ¨å¤šå°‘ã€‚åœ¨ä¸Šé¢æ‰€æœ‰çš„ä¾‹å­ä¸­ï¼Œstride sizeéƒ½æ˜¯1ã€‚filterçš„è¿ç»­ä½œç”¨æ˜¯é‡å çš„ã€‚æ›´å¤§çš„ stride size ä¼šå¾—åˆ°æ›´å°‘çš„filterä½œç”¨å’Œæ›´å°çš„è¾“å‡ºã€‚ä¸‹å›¾æ¥è‡ª<a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="external">Stanford cs231 website</a>ï¼Œæ˜¾ç¤ºäº†stride size 1 å’Œ stride size 2 åˆ†åˆ«ä½œç”¨åœ¨1ç»´è¾“å…¥çš„æƒ…å†µï¼š<br><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-10.18.08-AM.png" alt="" title="Convolution Stride Size. Left: Stride size 1. Right: Stride size 2. Source: http://cs231n.github.io/convolutional-networks/"><br>åœ¨æ–‡çŒ®ä¸­ï¼Œæˆ‘ä»¬å¸¸å¸¸çœ‹åˆ°stride sizeä¸º1ï¼Œä½†æ˜¯æ›´å¤§çš„stride sizeä¼šè®©ä½ æ„å»ºå‡ºè¡¨ç°å’Œ<a href="https://en.wikipedia.org/wiki/Recursive_neural_network" target="_blank" rel="external">Recursive Neural Network</a>(çœ‹èµ·æ¥åƒæ ‘)ç›¸ä¼¼çš„æ¨¡å‹ã€‚</p>
<h1 id="Pooling-layers"><a href="#Pooling-layers" class="headerlink" title="Pooling layers"></a>Pooling layers</h1><p>Convolutional Neural Networksçš„ä¸€ä¸ªå¾ˆé‡è¦çš„æ–¹é¢æ˜¯poolingå±‚ï¼Œå¸¸å¸¸åº”ç”¨åœ¨å·ç§¯å±‚åé¢ã€‚Poolingå±‚å­æŠ½æ ·ä»–ä»¬çš„è¾“å…¥ã€‚åšpoolingæœ€å¸¸ç”¨çš„æ–¹æ³•æ˜¯åœ¨æ¯ä¸€ä¸ªfilterçš„ç»“æœä¹‹ä¸Šåšä¸€ä¸ª\(max\)æ“ä½œã€‚ä½ ä¸éœ€è¦åœ¨æ•´ä¸ªçŸ©é˜µä¸Šåšpoolï¼Œä½ ä¹Ÿå¯ä»¥åœ¨ä¸€ä¸ªwindowä¸Šåšpoolã€‚æ¯”å¦‚ï¼Œä¸‹å›¾æ˜¾ç¤ºäº†ä¸€ä¸ªå¯¹äº2x2 windowçš„max pooling(åœ¨NLPä¸­ï¼Œæˆ‘ä»¬å¸¸å¸¸åº”ç”¨poolingåˆ°æ•´ä¸ªè¾“å‡ºï¼Œæ¯ä¸ªfilteråªè·å¾—ä¸€ä¸ªæ•°å€¼)ï¼š<br><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-2.18.38-PM.png" alt="" title="Max pooling in CNN. Source: http://cs231n.github.io/convolutional-networks/#pool"><br>ä¸ºä»€ä¹ˆpoolingï¼Ÿè¿™é‡Œæœ‰å‡ ä¸ªåŸå› ã€‚poolingçš„ä¸€ä¸ªç‰¹æ€§æ˜¯æä¾›äº†ä¸€ä¸ªå›ºå®šå¤§å°çš„è¾“å‡ºçŸ©é˜µï¼Œè¿™å¸¸å¸¸æ˜¯åˆ†ç±»éœ€è¦çš„ã€‚æ¯”å¦‚ï¼Œå¦‚æœä½ æœ‰1000ä¸ªfiltersï¼Œç„¶åä½ å¯¹æ¯ä¸ªéƒ½åº”ç”¨ max poolingï¼Œä½ ä¼šå¾—åˆ°ä¸€ä¸ª1000ç»´çš„è¾“å‡ºï¼Œå’Œfiltersçš„å¤§å°ï¼Œæˆ–è€…è¾“å…¥çš„å¤§å°æ— å…³ã€‚è¿™è®©ä½ å¯ä»¥ä½¿ç”¨å¯å˜é•¿çš„å¥å­ï¼Œå¯å˜å¤§å°çš„filtersï¼Œä½†æ˜¯æ€»æ˜¯å¾—åˆ°ç›¸åŒçš„è¾“å‡ºç»´åº¦ï¼Œç„¶åå–‚ç»™åˆ†ç±»å™¨ã€‚</p>
<p>Poolingä¹Ÿä¼šå‡å°‘è¾“å‡ºçš„ç»´åº¦ï¼Œä½†æ˜¯(å¸Œæœ›)ä¿æŒæœ€é‡è¦çš„ä¿¡æ¯ã€‚ä½ å¯ä»¥è®¤ä¸ºæ¯ä¸ªfilteréƒ½æ˜¯ç”¨æ¥æ¢æµ‹ç‰¹å®šçš„ç‰¹å¾çš„ï¼Œæ¯”å¦‚æ¢æµ‹å¥å­æ˜¯å¦åŒ…å«åƒâ€œnot amazingâ€çš„å¦å®šè¯ã€‚å¦‚æœè¿™ä¸ªçŸ­è¯­å‡ºç°åœ¨å¥å­ä¸­çš„æŸä¸ªåœ°æ–¹ï¼Œåº”ç”¨filteråˆ°é‚£ä¸ªåŒºåŸŸçš„ç»“æœæ˜¯è·å¾—ä¸€ä¸ªå¾ˆå¤§çš„å€¼ï¼Œä½†æ˜¯åœ¨å…¶ä»–åŒºåŸŸå¾—åˆ°çš„æ˜¯è¾ƒå°çš„å€¼ã€‚é€šè¿‡è¿›è¡Œmaxæ“ä½œï¼Œä½ å¯ä»¥ä¿æŒç‰¹å¾æ˜¯å¦å‡ºç°åœ¨å¥å­ä¸­çš„ä¿¡æ¯ï¼Œä½†æ˜¯ä½ ä¸¢å¤±äº†å®ƒåˆ°åº•å‡ºç°åœ¨å“ªçš„ä¿¡æ¯ã€‚ä½†æ˜¯å…³äºä½ç½®çš„ä¿¡æ¯ä¸æ˜¯çœŸçš„æœ‰ç”¨å—ï¼Ÿæ˜¯çš„ï¼Œå®ƒæ²¡æœ‰ç”¨ï¼Œè¿™å’Œn-gramsçš„è¯è¢‹æ¨¡å‹åšçš„äº‹æƒ…æœ‰ä¸€ç‚¹ç±»ä¼¼ã€‚ä½ ä¸¢å¤±äº†ä½ç½®çš„å…¨å±€ä¿¡æ¯(where in a sentence something happens)ï¼Œä½†æ˜¯ä½ ä¿æŒäº†filtersæ•è·çš„å±€éƒ¨ä¿¡æ¯ï¼Œæ¯”å¦‚â€œnot amazingâ€å’Œâ€œamazing notâ€å°±å¾ˆä¸åŒã€‚</p>
<p>åœ¨å›¾åƒè¯†åˆ«ä¸­ï¼Œpoolingä¹Ÿæä¾›äº†åŸºæœ¬çš„invariance åˆ° translating (shifting) å’Œ rotationã€‚å½“ä½ åœ¨ä¸€ä¸ªåŒºåŸŸè¿›è¡Œpoolingï¼Œè¾“å‡ºå¤§è‡´ä¸Šå°†ä¿æŒç›¸åŒï¼Œå³ä½¿ä½ shift/rotateå›¾åƒçš„ä¸€äº›åƒç´ ï¼Œå› ä¸ºmaxæ“ä½œä¼šæ‰¾åˆ°ç›¸åŒçš„å€¼ã€‚</p>
<h1 id="Channels"><a href="#Channels" class="headerlink" title="Channels"></a>Channels</h1><p>æœ€åä¸€ä¸ªéœ€è¦ç†è§£çš„æ¦‚å¿µæ˜¯channelsã€‚æ¯”å¦‚ï¼Œåœ¨å›¾åƒè¯†åˆ«ä¸­ï¼Œä½ é€šå¸¸æœ‰RGB (red, green, blue)é€šé“ã€‚ä½ å¯ä»¥è·¨é€šé“åº”ç”¨å·ç§¯ï¼Œä»¥ä¸åŒçš„æˆ–è€…ç›¸åŒçš„æƒé‡ã€‚åœ¨NLPä¸­ï¼Œä½ ä¹Ÿå¯ä»¥æƒ³è±¡æœ‰å¤šä¸ªé€šé“ï¼šä½ å¯ä»¥å¯¹ä¸åŒçš„word embeddings (æ¯”å¦‚<a href="https://code.google.com/p/word2vec/" target="_blank" rel="external">word2vec</a> å’Œ <a href="http://nlp.stanford.edu/projects/glove/" target="_blank" rel="external">GloVe</a>)æœ‰ä¸€ä¸ªå•ç‹¬çš„é€šé“ï¼Œæˆ–è€…å¯¹ç”¨ä¸åŒçš„è¯­è¨€è¡¨ç¤ºçš„ç›¸åŒçš„å¥å­/ä¸åŒå½¢å¼çš„çŸ­è¯­ï¼Œä½ å¯ä»¥æœ‰ä¸€ä¸ªé€šé“ã€‚</p>
<h1 id="Convolutional-Neural-Networks-Applied-to-NLP"><a href="#Convolutional-Neural-Networks-Applied-to-NLP" class="headerlink" title="Convolutional Neural Networks Applied to NLP"></a>Convolutional Neural Networks Applied to NLP</h1><p>ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹CNNsåœ¨NLPé¢†åŸŸçš„ä¸€äº›åº”ç”¨ã€‚æˆ‘ä¹Ÿä¼šé˜è¿°ä¸€äº›ç ”ç©¶ç»“æœï¼Œå½“ç„¶æˆ‘å¯èƒ½ä¼šé”™è¿‡è®¸å¤šæœ‰è¶£çš„åº”ç”¨(è¯·åœ¨è¯„è®ºä¸­è®©æˆ‘çŸ¥é“)ï¼Œä½†æ˜¯æˆ‘å¸Œæœ›è‡³å°‘åŒ…å«ä¸€äº›å—æ¬¢è¿çš„ç»“è®ºã€‚</p>
<p>å¯¹äºCNNsåº”ç”¨åœ¨NLPï¼Œæœ€è‡ªç„¶çš„ä¼¼ä¹æ˜¯åˆ†ç±»ä»»åŠ¡ï¼Œæ¯”å¦‚æƒ…æ„Ÿåˆ†ç±»ï¼Œåƒåœ¾è¿‡æ»¤æˆ–è€…ä¸»é¢˜åˆ†ç±»ã€‚å·ç§¯å’Œpoolingæ“ä½œä¼šä¸¢å¤±wordsçš„å±€éƒ¨é¡ºåºçš„ä¿¡æ¯ï¼Œå› æ­¤å¦‚è¯æ€§æ ‡æ³¨æˆ–è€…å‘½åå®ä½“è¯†åˆ«çš„åºåˆ—æ ‡æ³¨è¾ƒéš¾åº”ç”¨åˆ°çº¯ç¢çš„CNNæ¶æ„(ä½†æ˜¯ä¸æ˜¯ä¸å¯èƒ½ï¼Œä½ å¯ä»¥åŠ å…¥è¾“å…¥çš„ä½ç½®ç‰¹å¾)ä¸­ã€‚</p>
<p>[<a href="http://arxiv.org/abs/1408.5882.pdf" target="_blank" rel="external">1</a>] åœ¨å„ç§åˆ†ç±»(ä¸»è¦ç”±æƒ…æ„Ÿåˆ†æï¼Œä¸»é¢˜åˆ†ç±»ä»»åŠ¡ç»„æˆ)æ•°æ®é›†ä¸Šè¯„ä»·CNNæ¶æ„ã€‚åœ¨è·¨æ•°æ®é›†ä¸Šï¼ŒCNNæ¶æ„å–å¾—äº†éå¸¸å¥½çš„è¡¨ç°ï¼Œç”šè‡³æœ‰ä¸€äº›éå¸¸å¥½ã€‚ä»¤äººæƒŠè®¶åœ°æ˜¯è¿™ç¯‡è®ºæ–‡ä¸­ä½¿ç”¨çš„ç½‘ç»œç›¸å½“ç®€å•ï¼Œè¾“å…¥å±‚æ˜¯ç”±ç›¸è¿çš„word2vec word embeddings ç»„æˆçš„å¥å­ã€‚ç„¶åæ˜¯æœ‰å¤šä¸ªfiltersçš„å·ç§¯å±‚ï¼Œmax-poolingå±‚ï¼Œæœ€åæ˜¯ä¸€ä¸ªsoftmaxåˆ†ç±»å™¨ã€‚è¿™ç¯‡è®ºæ–‡ä¹Ÿç”¨ä¸¤ä¸ªä¸åŒçš„é€šé“è¿›è¡Œäº†å®éªŒï¼Œä¸€ä¸ªæ˜¯é™æ€çš„word embeddingsï¼Œä¸€ä¸ªæ˜¯åŠ¨æ€çš„word embeddingsï¼Œä¹Ÿå°±æ˜¯åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œä¸€ä¸ªé€šé“è¢«è°ƒæ•´ï¼Œå¦ä¸€ä¸ªä¸åŠ¨ã€‚ä¸€ä¸ªç›¸ä¼¼ä½†æ›´å¤æ‚çš„æ¶æ„åœ¨[<a href="http://arxiv.org/abs/1404.2188" target="_blank" rel="external">2</a>]ä¸­æ›´æ—©è¢«æå‡ºã€‚[<a href="http://www.aclweb.org/anthology/P15-2058" target="_blank" rel="external">6</a>]å¢åŠ äº†ä¸€ä¸ªé¢å¤–çš„å±‚å¯¹è¿™ä¸ªç½‘ç»œæ¶æ„è¿›è¡Œâ€è¯­ä¹‰èšç±»â€ã€‚<br><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-8.03.47-AM.png" alt="" title="Kim, Y. (2014). Convolutional Neural Networks for Sentence Classification"></p>
<p><a href="">4</a> Trains a CNN from scratch, without the need for for pre-trained word vectors like word2vec or GloVe. It applies convolutions directly to one-hot vectors. The author also proposes a space-efficient bag-of-words-like representation for the input data, reducing the number of parameters the network needs to learn. In <a href="">5</a> the author  extends the model with an additional unsupervised â€œregion embeddingâ€ that is learned using a CNN  predicting the context of text regions. The approach in these papers seems to work well for long-form texts (like movie reviews), but their performance on short texts (like tweets) isnâ€™t clear. Intuitively, it makes sense that using pre-trained word embeddings for short texts would yield larger gains than using them for long texts.</p>
<p>Building a CNN architecture means that there are many hyperparameters to choose from, some of which I presented above: Input represenations (word2vec, GloVe, one-hot), number and sizes of convolution filters, pooling strategies (max, average), and activation functions (ReLU, tanh). <a href="">7</a> performs an empirical evaluation on the effect of varying hyperparameters in CNN architectures, investigating their impact on performance and variance over multiple runs. If you are looking to implement your own CNN for text classification, using the results of this paper as a starting point would be an excellent idea. A few results that stand out are that max-pooling always beat average pooling, that the ideal filter sizes are important but task-dependent, and that regularization doesnâ€™t seem to make a big different in the NLP tasks that were considered. A caveat of this research is that all the datasets were quite similar in terms of their document length, so the same guidelines may not apply to data that looks considerably different.</p>
<p><a href="">8</a> explores CNNs for  Relation Extraction and Relation Classification tasks. In addition to the word vectors, the authors use the relative positions of words to the entities of interest as an input to the convolutional layer. This models assumes that the positions of the entities are given, and that each example input contains one relation. <a href="">9</a> and <a href="">10</a> have explored similar models.<br>Another interesting use case of CNNs in NLP can be found in <a href="">11</a> and <a href="">12</a>, coming out of Microsoft Research. These papers describe how to learn semantically meaningful representations of sentences that can be used for Information Retrieval. The example given in the papers includes recommending potentially interesting documents to users based on what they are currently reading. The sentence representations are trained based on search engine log data.</p>
<p>Most CNN architectures learn embeddings (low-dimensional representations) for words and sentences in one way or another as part of their training procedure. Not all papers though focus on this aspect of training or investigate how meaningful the learned embeddings are. <a href="">13</a> presents a CNN architecture to predict hashtags for Facebook posts, while at the same time generating meaningful embeddings for words and sentences. These learned embeddings are then successfully applied to another task â€“ recommending potentially interesting documents to users, trained based on clickstream data.</p>
<h1 id="Character-level-CNNS"><a href="#Character-level-CNNS" class="headerlink" title="Character-level CNNS"></a>Character-level CNNS</h1><p>ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è¯´çš„æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯åŸºäºwordsçš„ã€‚ä½†æ˜¯ä¹Ÿæœ‰ç ”ç©¶æŠŠCNNsç›´æ¥åº”ç”¨åˆ°charactersçš„ã€‚[<a href="http://jmlr.org/proceedings/papers/v32/santos14.pdf" target="_blank" rel="external">14</a>] å­¦ä¹ äº†character-level embeddingsï¼Œç”¨é¢„è®­ç»ƒçš„word embeddingsç»“åˆå®ƒä»¬ï¼Œç„¶åç”¨CNNè¿›è¡Œè¯æ€§æ ‡æ³¨ã€‚[<a href="http://arxiv.org/abs/1509.01626" target="_blank" rel="external">15</a>][<a href="http://arxiv.org/abs/1502.01710" target="_blank" rel="external">16</a>] æ¢ç´¢äº†CNNsçš„ç”¨æ³•ï¼Œç›´æ¥ä»charactersä¸­å­¦ä¹ ï¼Œä¸éœ€è¦ä»»ä½•é¢„è®­ç»ƒçš„embeddingsã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½œè€…ç”¨äº†ä¸€ä¸ªç›¸å½“æ·±çš„ç½‘ç»œï¼Œæœ‰9å±‚ï¼Œç„¶åå°†å®ƒåº”ç”¨åˆ°æƒ…æ„Ÿåˆ†æå’Œæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€‚ç»“æœæ˜¾ç¤ºç›´æ¥ä»character-levelçš„è¾“å…¥ä¸­å­¦ä¹ åœ¨å¤§æ•°æ®é›†(ç™¾ä¸‡æ ·æœ¬)ä¸Šè¡¨ç°åœ°ç›¸å½“å¥½ï¼Œä½†æ˜¯åœ¨è¾ƒå°çš„æ•°æ®é›†(å‡ ç™¾å‡ åƒä¸ªæ ·æœ¬)ä¸Šçš„è¡¨ç°ä¸å¦‚ç®€å•çš„æ¨¡å‹ã€‚[<a href="http://arxiv.org/abs/1508.06615" target="_blank" rel="external">17</a>] æ¢ç´¢äº†character-level convolutions åœ¨è¯­è¨€æ¨¡å‹ä¸Šçš„åº”ç”¨ï¼Œåœ¨æ¯ä¸€æ­¥ï¼Œä½¿ç”¨character-level CNN çš„è¾“å‡ºä½œä¸º LSTM çš„è¾“å…¥ã€‚ç›¸åŒçš„æ¨¡å‹åº”ç”¨åœ¨å„ç§å„æ ·çš„è¯­è¨€ã€‚</p>
<p>ä»¤äººå…´å¥‹çš„æ˜¯ä¸Šé¢çš„è®ºæ–‡åŸºæœ¬éƒ½æ˜¯åœ¨è¿‡å»çš„1-2å¹´å‡ºç‰ˆçš„ã€‚æ˜¾ç„¶ä¹‹å‰å°±å·²ç»æœ‰CNNsåœ¨NLPçš„ä¼˜ç§€æˆæœã€‚æ¯”å¦‚<a href="http://arxiv.org/abs/1103.0398" target="_blank" rel="external">Natural Language Processing (almost) from Scratch</a>ï¼Œä½†æ˜¯æ–°çš„ç ”ç©¶æˆæœå’Œæœ€å…ˆè¿›çš„ç³»ç»Ÿå‡ºç‰ˆçš„æ­¥è°ƒå¾ˆæ˜¾ç„¶æ­£åœ¨åŠ é€Ÿã€‚</p>

      
    </div>

    <div>
      
        
      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/cnn/" rel="tag">#CNN</a>
          
            <a href="/tags/classification/" rel="tag">#Classification</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/09/14/å—é™æ³¢å°”æ»‹æ›¼æœº/" rel="next" title="å—é™æ³¢å°”æ»‹æ›¼æœº">
                <i class="fa fa-chevron-left"></i> å—é™æ³¢å°”æ»‹æ›¼æœº
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/09/22/implementing-a-cnn-for-text-classification-in-tensorflow/" rel="prev" title="Implementing a CNN for Text Classification in Tensorflow">
                Implementing a CNN for Text Classification in Tensorflow <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2016/09/22/understanding-convolutional-neural-networks-for-nlp/"
           data-title="Understanding Convolutional Neural Networks for NLP" data-url="http://github.com/kiseliu/2016/09/22/understanding-convolutional-neural-networks-for-nlp/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/myname.png"
               alt="kiseliu" />
          <p class="site-author-name" itemprop="name">kiseliu</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/">
              <span class="site-state-item-count">85</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/">
                
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">categories</span>
                
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/">
              
                <span class="site-state-item-count">54</span>
                <span class="site-state-item-name">tags</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/kiseliu" target="_blank" title="Github">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  Github
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/kiseliu" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  LinkedIn
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/kiseliu" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#What-is-convolution"><span class="nav-number">1.</span> <span class="nav-text">What is convolution?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#What-are-convolutional-neural-networks"><span class="nav-number">2.</span> <span class="nav-text">What are convolutional neural networks?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#So-how-does-any-of-this-apply-to-NLP"><span class="nav-number">3.</span> <span class="nav-text">So, how does any of this apply to NLP?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CNN-Hyperparameters"><span class="nav-number">4.</span> <span class="nav-text">CNN Hyperparameters</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Narrow-VS-Wide-Convolution"><span class="nav-number">5.</span> <span class="nav-text">Narrow VS. Wide Convolution</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Stride-size"><span class="nav-number">6.</span> <span class="nav-text">Stride size</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Pooling-layers"><span class="nav-number">7.</span> <span class="nav-text">Pooling layers</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Channels"><span class="nav-number">8.</span> <span class="nav-text">Channels</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Convolutional-Neural-Networks-Applied-to-NLP"><span class="nav-number">9.</span> <span class="nav-text">Convolutional Neural Networks Applied to NLP</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Character-level-CNNS"><span class="nav-number">10.</span> <span class="nav-text">Character-level CNNS</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">kiseliu</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"kiseliu"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
  






  
  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
<script type="text/javascript" async src="//push.zhanzhang.baidu.com/push.js">
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


</body>
</html>
